import os
import re
import shutil
import pandas as pd
import warnings

from glob import glob
from tqdm import tqdm
from build_dataframe import build_dataframe
from build_report import build_report

warnings.filterwarnings("ignore")

# Load configuration variables
raw_data_path = config.get("raw_data", None)
list_of_samples = config.get("samples", None)
install_path = config.get("install_path", None)
shovill_cpus = config.get("shovill_cpu_cores", 1)
prokka_cpus = config.get("prokka_cpu_cores", 1)
roary_cpus = config.get("roary_cpu_cores", 1)

# Ensure the raw_data directory exists
os.makedirs("raw_data", exist_ok=True)

with open(f"{install_path}/layout.html", 'r') as file:
    html_string = file.read()

# ================= Utility Functions =================

def list_fastq_files(path):
    """Returns a list of all .fastq.gz files in the specified path."""
    return [f for f in glob(os.path.join(path, "*.fastq.gz"))]

def get_core_sample_name(filename):
    """Extracts the core sample name by removing _R1 or _R2 and other suffixes."""
    pattern = re.compile(r'^(?P<sample>.+?)[_\.\-]?R[12].*\.fastq\.gz$', re.IGNORECASE)
    match = pattern.match(os.path.basename(filename))
    return match.group("sample") if match else None

def build_fastq_pairs(fastq_files):
    """Pairs R1 and R2 files based on sample names."""
    pairs = {}
    for file in fastq_files:
        sample = get_core_sample_name(file)
        if sample:
            if sample not in pairs:
                pairs[sample] = {}
            if "_R1" in file or "R1" in file:
                pairs[sample]["R1"] = file
            elif "_R2" in file or "R2" in file:
                pairs[sample]["R2"] = file
    # Filter out incomplete pairs
    return {s: p for s, p in pairs.items() if "R1" in p and "R2" in p}


# ================= Data Preparation =================

fastq_files = list_fastq_files("raw_data")
file_names = [os.path.basename(f).replace(".fastq.gz", "") for f in fastq_files]
sample_pairs = build_fastq_pairs(fastq_files)
sample_names = list(sample_pairs.keys())

# ================= Snakemake Workflow =================

rule all:
    input:
        html=expand("fastqc/{file}_fastqc.html", file=file_names),
        html_zip=expand("fastqc/{file}_fastqc.zip", file=file_names),
        shovill=expand(
            "results/{sample}/shovill/contigs.fa",
            sample=sample_pairs.keys()
        ),
        abricate_ncbi=expand(
            "results/{sample}/abricate_ncbi.tsv",
            sample=sample_pairs.keys()
        ),
        abricate_plasmidfinder=expand(
            "results/{sample}/abricate_plasmidfinder.tsv",
            sample=sample_pairs.keys()
        ),
        abricate_vfdb=expand(
            "results/{sample}/abricate_vfdb.tsv",
            sample=sample_pairs.keys()
        ),
        mlst=expand(
            "results/{sample}/mlst.tsv",
            sample=sample_pairs.keys()
        ),
        dataframe="dataframe/results.csv",
        prokka=expand(
            "results/{sample}/prokka/{sample}.gff",
            sample=sample_pairs.keys()
        ),
        pangenome_flag="flags/.pangenome",
        Box_Contig_Length="report/Contig_Length_Box_Plot.html",
        DF_Full_Table="report/Gene_Table.html",
        DF_Reads_Table="report/FastQC_Table.html",
        Heatmap_Pangenomic="report/Pangenomic_Heatmap.html",
        Heatmap_Plasmids_Full_Figure_Coverage="report/Plasmid_Gene_Heatmap.html",
        Heatmap_Resistance_Full_Figure="report/Resistance_Heatmap.html",
        Heatmap_Virulence_Full_Figure_Coverage="report/Virulence_Heatmap.html",
        Pangenome_Pie_Chart="report/Pangenomic_Pie_Chart.html",
        Scatter_Contig_Length="report/Contig_Length_Scatter_Plot.html",
        Subtype_HTML_String="report/Resistance_Profile.html",
        Sunburst_Figure="report/MLST_Sunburst_Plot.html",
        flag="flags/.report"

rule fastqc:
    input:
        fastq_files="raw_data/{file}.fastq.gz"
    output:
        html="fastqc/{file}_fastqc.html",
        html_zip="fastqc/{file}_fastqc.zip",
    conda:
        "fastqc_env.yml"
    shell:
        """
        mkdir -p fastqc
        fastqc {input.fastq_files} -o fastqc
        """

rule shovill:
    input:
        R1=lambda wildcards: sample_pairs[wildcards.sample]["R1"],
        R2=lambda wildcards: sample_pairs[wildcards.sample]["R2"]
    output:
        assembly="results/{sample}/shovill/contigs.fa",
        gfa="results/{sample}/shovill/contigs.gfa",
        corrections="results/{sample}/shovill/shovill.corrections",
        log="results/{sample}/shovill/shovill.log",
        spades="results/{sample}/shovill/spades.fasta"
    threads:
        shovill_cpus
    conda:
        "shovill_env.yml"
    shell:
        "shovill --trim --outdir results/{wildcards.sample}/shovill --R1 {input.R1} --R2 {input.R2} --force --cpus {threads}"

rule abricate_ncbi:
    input:
        assembly="results/{sample}/shovill/contigs.fa"
    output:
        abricate="results/{sample}/abricate_ncbi.tsv"
    conda:
        "abricate_env.yml"
    shell:
        "abricate --db ncbi {input.assembly} > {output.abricate}"

rule abricate_plasmidfinder:
    input:
        assembly="results/{sample}/shovill/contigs.fa"
    output:
        abricate="results/{sample}/abricate_plasmidfinder.tsv"
    conda:
        "abricate_env.yml"
    shell:
        "abricate --db plasmidfinder {input.assembly} > {output.abricate}"

rule abricate_vfdb:
    input:
        assembly="results/{sample}/shovill/contigs.fa"
    output:
        abricate="results/{sample}/abricate_vfdb.tsv"
    conda:
        "abricate_env.yml"
    shell:
        "abricate --db vfdb {input.assembly} > {output.abricate}"

rule mlst:
    input:
        assembly="results/{sample}/shovill/contigs.fa"
    output:
        mlst="results/{sample}/mlst.tsv"
    conda:
        "mlst_env.yml"
    shell:
        "mlst {input.assembly} > {output.mlst}"

rule prokka:
    input:
        assembly="results/{sample}/shovill/contigs.fa"
    output:
        prokka="results/{sample}/prokka/{sample}.gff",
        err="results/{sample}/prokka/{sample}.err",
        faa="results/{sample}/prokka/{sample}.faa",
        ffn="results/{sample}/prokka/{sample}.ffn",
        fna="results/{sample}/prokka/{sample}.fna",
        fsa="results/{sample}/prokka/{sample}.fsa",
        gbk="results/{sample}/prokka/{sample}.gbk",
        log="results/{sample}/prokka/{sample}.log",
        sqn="results/{sample}/prokka/{sample}.sqn",
        tbl="results/{sample}/prokka/{sample}.tbl",
        tsv="results/{sample}/prokka/{sample}.tsv",
        txt="results/{sample}/prokka/{sample}.txt"
    conda:
        "prokka_env.yml"
    shell:
        "prokka --centre X --compliant {input.assembly} --outdir results/{wildcards.sample}/prokka/" + f" --force --cpus {prokka_cpus}" + " --prefix {wildcards.sample}"

checkpoint build_dataframe:
    input:
        html=expand("fastqc/{file}_fastqc.html", file=file_names),
        html_zip=expand("fastqc/{file}_fastqc.zip", file=file_names),
        abricate_ncbi=expand("results/{sample}/abricate_ncbi.tsv", sample=sample_names),
        abricate_plasmidfinder=expand("results/{sample}/abricate_plasmidfinder.tsv", sample=sample_names),
        abricate_vfdb=expand("results/{sample}/abricate_vfdb.tsv", sample=sample_names),
        mlst=expand("results/{sample}/mlst.tsv", sample=sample_names),
        shovill=expand("results/{sample}/shovill/contigs.fa", sample=sample_names)
    output:
        dataframe="dataframe/results.csv"
    run:
        build_dataframe()

# Helper function to get the species based on the sample
def get_species_list_for_roary():
    df = pd.read_csv("dataframe/results.csv", dtype={'SAMPLE': str})

    # Group by species and samples
    df = df.groupby(["SPECIES", "SAMPLE"]).size().reset_index()
    df = df[['SPECIES', 'SAMPLE']]

    # Group by species and count the number of samples
    df_grouped = df.groupby("SPECIES").count().reset_index()

    # Get the species that have more than one sample
    eligeble_species = df_grouped.loc[df_grouped["SAMPLE"] > 1, "SPECIES"].tolist()

    df.loc[df["SPECIES"].isin(eligeble_species), "SAMPLE"].tolist()

    # Return only the species that have more than one sample
    return df.loc[df["SPECIES"].isin(eligeble_species), "SPECIES"].tolist()

def get_species_list_for_roary_unique():
    df = pd.read_csv("dataframe/results.csv", dtype={'SAMPLE': str})

    # Group by species and samples
    df = df.groupby(["SPECIES", "SAMPLE"]).size().reset_index()
    df = df[['SPECIES', 'SAMPLE']]

    df_grouped = df.groupby("SPECIES").count().reset_index()

    eligeble_species = df_grouped.loc[df_grouped["SAMPLE"] > 1, "SPECIES"].tolist()

    return list(set(df.loc[df["SPECIES"].isin(eligeble_species), "SPECIES"].tolist()))

def get_pangenome_prokka_outputs(wildcards):
    # Get the output of the build_dataframe checkpoint
    df_output = checkpoints.build_dataframe.get().output[0]
    df = pd.read_csv(df_output, dtype={'SAMPLE': str})
    
    # Get species with more than one sample
    df_grouped = df.groupby('SPECIES')['SAMPLE'].nunique().reset_index()
    eligible_species = df_grouped.loc[df_grouped['SAMPLE'] > 1, 'SPECIES'].tolist()
    
    # Get the list of Prokka outputs needed
    prokka_files = []
    for species in eligible_species:
        samples = df.loc[df['SPECIES'] == species, 'SAMPLE'].unique()
        for sample in samples:
            prokka_files.append(f"results/{sample}/prokka/{sample}.gff")
    return prokka_files

rule pangenome:
    input:
        dataframe="dataframe/results.csv",
        prokka_outputs=get_pangenome_prokka_outputs
    output:
        "flags/.pangenome"
    conda:
        "roary_env.yml"
    script:
        "run_roary.py"

rule build_report:
    input:
        pangenome="flags/.pangenome",
    output:
        Box_Contig_Length="report/Contig_Length_Box_Plot.html",
        DF_Full_Table="report/Gene_Table.html",
        DF_Reads_Table="report/FastQC_Table.html",
        Heatmap_Pangenomic="report/Pangenomic_Heatmap.html",
        Heatmap_Plasmids_Full_Figure_Coverage="report/Plasmid_Gene_Heatmap.html",
        Heatmap_Resistance_Full_Figure="report/Resistance_Heatmap.html",
        Heatmap_Virulence_Full_Figure_Coverage="report/Virulence_Heatmap.html",
        Pangenome_Pie_Chart="report/Pangenomic_Pie_Chart.html",
        Scatter_Contig_Length="report/Contig_Length_Scatter_Plot.html",
        Subtype_HTML_String="report/Resistance_Profile.html",
        Sunburst_Figure="report/MLST_Sunburst_Plot.html",
        flag="flags/.report"
    run:
        build_report(html_string)
